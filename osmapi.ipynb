{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee984c0",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "* some block numbers have XX used as anonymization; eg. 030XX means somewhere on 3000 block, 014XX means somwhere on 1400 block\n",
    "* will either need to use the street name or approximate address (030XX -> 3000/3012/3014)\n",
    "* some address are truncated\n",
    "* \"&\" used for intersections\n",
    "\n",
    "* Some coordinates do not exactly match up to given address; many are off by an order of thousands of feet\n",
    "* The final df in this case will have a lat,lng, final_lat, final_lng columns; final_lat, final_lng is either:\n",
    "    *** the coords specified in the original df\n",
    "    ***the imputed coords based on address estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b9abb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0011e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/4yf7b9tn1t1ck0mv8h93dssc0000gn/T/ipykernel_2223/1773643332.py:2: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"policing.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_row_number</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>location</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>district</th>\n",
       "      <th>zone</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>...</th>\n",
       "      <th>search_person</th>\n",
       "      <th>search_vehicle</th>\n",
       "      <th>search_basis</th>\n",
       "      <th>reason_for_stop</th>\n",
       "      <th>vehicle_color</th>\n",
       "      <th>vehicle_make</th>\n",
       "      <th>vehicle_model</th>\n",
       "      <th>vehicle_year</th>\n",
       "      <th>raw_actions_taken</th>\n",
       "      <th>raw_subject_race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>4260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>E</td>\n",
       "      <td>26.0</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAFFIC VIOLATION</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>CARAVAN</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9087</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>37.0</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAFFIC VIOLATION</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>MURANO</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9086</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>37.0</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAFFIC VIOLATION</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>MURANO</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>50400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>I</td>\n",
       "      <td>96.0</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAFFIC VIOLATION</td>\n",
       "      <td>GRAY</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>GRAND CHEROKEE</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>7560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>17.0</td>\n",
       "      <td>black</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CALL FOR SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  raw_row_number        date   time location  lat  lng district zone  \\\n",
       "0              1  2010-01-01   4260      NaN  NaN  NaN        6    E   \n",
       "1           9087  2010-01-01   5340      NaN  NaN  NaN        7    C   \n",
       "2           9086  2010-01-01   5340      NaN  NaN  NaN        7    C   \n",
       "3            267  2010-01-01  50400      NaN  NaN  NaN        7    I   \n",
       "4              2  2010-01-01   7560      NaN  NaN  NaN        5    D   \n",
       "\n",
       "   subject_age subject_race  ... search_person search_vehicle search_basis  \\\n",
       "0         26.0        black  ...         False          False          NaN   \n",
       "1         37.0        black  ...         False          False          NaN   \n",
       "2         37.0        black  ...         False          False          NaN   \n",
       "3         96.0        black  ...         False          False          NaN   \n",
       "4         17.0        black  ...         False          False          NaN   \n",
       "\n",
       "     reason_for_stop  vehicle_color  vehicle_make   vehicle_model  \\\n",
       "0  TRAFFIC VIOLATION          BLACK         DODGE         CARAVAN   \n",
       "1  TRAFFIC VIOLATION           BLUE        NISSAN          MURANO   \n",
       "2  TRAFFIC VIOLATION           BLUE        NISSAN          MURANO   \n",
       "3  TRAFFIC VIOLATION           GRAY          JEEP  GRAND CHEROKEE   \n",
       "4   CALL FOR SERVICE            NaN           NaN             NaN   \n",
       "\n",
       "  vehicle_year raw_actions_taken raw_subject_race  \n",
       "0       2005.0               NaN            BLACK  \n",
       "1       2005.0               NaN            BLACK  \n",
       "2       2005.0               NaN            BLACK  \n",
       "3       2003.0               NaN            BLACK  \n",
       "4          NaN               NaN            BLACK  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in SOPP data\n",
    "df = pd.read_csv(\"policing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f028e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TRAFFIC VIOLATION', 'CALL FOR SERVICE', 'SUSPECT PERSON',\n",
       "       'CITIZEN CONTACT', 'OTHER', 'FLAGGED DOWN', 'JUVENILE VIOLATION',\n",
       "       'SUSPECT VEHICLE', 'CRIMINAL VIOLATION', 'PRESENT AT CRIME SCENE',\n",
       "       'TRAFFIC VIOLATION|OTHER',\n",
       "       'SUSPECT VEHICLE|SUSPECT PERSON|SUSPECT PERSON',\n",
       "       'TRAFFIC VIOLATION|CALL FOR SERVICE',\n",
       "       'CITIZEN CONTACT|FLAGGED DOWN',\n",
       "       'CALL FOR SERVICE|TRAFFIC VIOLATION',\n",
       "       'CRIMINAL VIOLATION|TRAFFIC VIOLATION',\n",
       "       'TRAFFIC VIOLATION|OTHER|OTHER'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reason_for_stop\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b268a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['030XX Elysian Fields Ave', '014XX N Claiborne Ave', '030XX Tchoupitoulas St', 'Leonidas St & S Claiborne Ave', 'Decatur St & Toulouse St', '017XX Spain St', 'Bloomingdale Ct & Erato St', '007XX Canal St', 'Memphis St & Robert E Lee Blvd', 'Forshey St & S Carrollton Ave', 'Palmyra St & S Broad St', 'N Claiborne Ave & Saint Maurice Ave', '010XX Caffin Ave', 'Canal Blvd & Filmore Ave', 'Elysian Fields Ave & Robert E Le', 'Martin Luther King Jr Blvd & S Liberty St', '001XX 40th St', 'Igor Sikorsky Dr & Stars & Str', '004XX Belleville St', 'New Orleans St & N Rocheblave St', '021XX Franklin Ave', '012XX Royal St', 'S Carrollton Ave & Tulane Ave', '032XX Garden Oaks Dr', 'Tchoupitoulas St & Jefferson Ave', '018XX Saint Thomas St', '014XX Saint Charles Ave', '018XX Marais St', 'Saint Andrew St & Magnolia St', 'Gen Diaz St & Porteous St']\n",
      "proportion of data that has location: 81.25610241909656\n",
      "unique locations: 12995\n"
     ]
    }
   ],
   "source": [
    "# location data sample\n",
    "print(df['location'].dropna().sample(30, random_state=42).tolist())\n",
    "\n",
    "\n",
    "#proportion of data that has a location\n",
    "print(f\"proportion of data that has location: {(df['location'].notna().mean()) * 100}\")\n",
    "\n",
    "# unique locations\n",
    "unique_locations = df[df['lat'].isna() & df['location'].notna()]['location'].unique()\n",
    "print(f\"unique locations: {len(unique_locations)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7c7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of data that has coordinates\n",
      "50.85180006717543\n",
      "50.85180006717543\n"
     ]
    }
   ],
   "source": [
    "# proportion of data with coordinates\n",
    "print(\"proportion of data that has coordinates\")\n",
    "print(100 - (sum(df[\"lat\"].isnull())/len(df[\"lat\"]) * 100))\n",
    "print(100 - (sum(df[\"lng\"].isnull())/len(df[\"lng\"]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6ff051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows missing coords: 155698\n",
      "Unique locations to geocode: 12995\n"
     ]
    }
   ],
   "source": [
    "# get rows missing lat/lng but having location \n",
    "missing_coords = df[df[\"lat\"].isna() & df[\"location\"].notna()]\n",
    "\n",
    "# get unique locations\n",
    "unique_locs_df = pd.DataFrame(missing_coords['location'].unique(), columns=['location'])\n",
    "\n",
    "print(f\"Total rows missing coords: {len(missing_coords)}\")\n",
    "print(f\"Unique locations to geocode: {len(unique_locs_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0980e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>029XX Vespasian Blvd</td>\n",
       "      <td>2900 Vespasian Blvd, New Orleans, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>033XX Gen De Gaulle Dr</td>\n",
       "      <td>3300 Gen De Gaulle Dr, New Orleans, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>076XX Fieldston Rd</td>\n",
       "      <td>7600 Fieldston Rd, New Orleans, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005XX Bourbon St</td>\n",
       "      <td>500 Bourbon St, New Orleans, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>020XX La Salle St</td>\n",
       "      <td>2000 La Salle St, New Orleans, LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location                                   query\n",
       "0    029XX Vespasian Blvd    2900 Vespasian Blvd, New Orleans, LA\n",
       "1  033XX Gen De Gaulle Dr  3300 Gen De Gaulle Dr, New Orleans, LA\n",
       "2      076XX Fieldston Rd      7600 Fieldston Rd, New Orleans, LA\n",
       "3        005XX Bourbon St         500 Bourbon St, New Orleans, LA\n",
       "4       020XX La Salle St       2000 La Salle St, New Orleans, LA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string cleaning \n",
    "def clean_location(loc):\n",
    "    if not isinstance(loc, str):\n",
    "        return None\n",
    "    loc = loc.strip()\n",
    "    loc = re.sub(r'(\\d+)XX', lambda m: str(int(m.group(1))) + '00', loc)\n",
    "    return loc + \", New Orleans, LA\"\n",
    "\n",
    "unique_locs_df['query'] = unique_locs_df['location'].apply(clean_location)\n",
    "unique_locs_df = unique_locs_df.drop(columns=['imp_lat', 'imp_lng'], errors='ignore')\n",
    "unique_locs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e42cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will download the csv locally; takes 1+ hours\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"sds357-project\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1, error_wait_seconds=5)\n",
    "\n",
    "# Resume from where left off if file exists\n",
    "if os.path.exists('geocoded_locations.csv'):\n",
    "    already_done = pd.read_csv('geocoded_locations.csv')\n",
    "    unique_locs_df = unique_locs_df.merge(already_done[['location', 'imp_lat', 'imp_lng']], on='location', how='left')\n",
    "    to_geocode = unique_locs_df[unique_locs_df['imp_lat'].isna()]\n",
    "    print(f\"Resuming — {len(already_done) - to_geocode.shape[0]} already done, {len(to_geocode)} remaining\")\n",
    "else:\n",
    "    unique_locs_df['imp_lat'] = None\n",
    "    unique_locs_df['imp_lng'] = None\n",
    "    to_geocode = unique_locs_df\n",
    "    print(f\"Starting fresh — {len(to_geocode)} locations to geocode\")\n",
    "\n",
    "for idx, row in tqdm(to_geocode.iterrows(), total=len(to_geocode)):\n",
    "    result = geocode(row['query'])\n",
    "    unique_locs_df.at[idx, 'imp_lat'] = result.latitude if result else None\n",
    "    unique_locs_df.at[idx, 'imp_lng'] = result.longitude if result else None\n",
    "    if idx % 100 == 0:\n",
    "        unique_locs_df[['location', 'query', 'imp_lat', 'imp_lng']].to_csv('geocoded_locations.csv', index=False)\n",
    "\n",
    "# Final save\n",
    "unique_locs_df[['location', 'query', 'imp_lat', 'imp_lng']].to_csv('geocoded_locations.csv', index=False)\n",
    "print(f\"Successfully geocoded: {unique_locs_df['imp_lat'].notna().sum()} / {len(unique_locs_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88f86a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total locations: 12995\n",
      "successfully geocoded: 1\n",
      "success rate: 7.695267410542516e-05\n"
     ]
    }
   ],
   "source": [
    "geocoded_df = pd.read_csv('geocoded_locations.csv')\n",
    "\n",
    "print(f\"total locations: {len(geocoded_df)}\")\n",
    "print(f\"successfully geocoded: {geocoded_df['imp_lat'].notna().sum()}\")\n",
    "print(f\"success rate: {geocoded_df['imp_lat'].notna().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77033d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: 1\n",
      "out of bounds: 12994\n"
     ]
    }
   ],
   "source": [
    "# bounding box filter\n",
    "lat_min, lat_max = 29.866661, 30.19866\n",
    "lng_min, lng_max = -90.140074, -89.625053\n",
    "\n",
    "geocoded_df['valid'] = (\n",
    "    geocoded_df['imp_lat'].between(lat_min, lat_max) &\n",
    "    geocoded_df['imp_lng'].between(lng_min, lng_max)\n",
    ")\n",
    "\n",
    "# set out of bounds coords to None\n",
    "geocoded_df.loc[~geocoded_df['valid'], ['imp_lat', 'imp_lng']] = None\n",
    "\n",
    "print(f\"valid: {geocoded_df['imp_lat'].notna().sum()}\")\n",
    "print(f\"out of bounds: {(~geocoded_df['valid'] & geocoded_df['valid'].notna()).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c21016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original coords: 260408\n",
      "imputed coords: 3\n",
      "still missing: 251681\n",
      "coverage: 50.9%\n"
     ]
    }
   ],
   "source": [
    "#merge geocoded_locations with main df\n",
    "df = df.drop(columns=['imp_lat', 'imp_lng', 'final_lat', 'final_lng'], errors='ignore')\n",
    "\n",
    "df = df.merge(geocoded_df[['location', 'imp_lat', 'imp_lng']], on='location', how='left')\n",
    "\n",
    "# use original coords where available, fall back to imputed\n",
    "df['final_lat'] = df['lat'].fillna(df['imp_lat'])\n",
    "df['final_lng'] = df['lng'].fillna(df['imp_lng'])\n",
    "\n",
    "print(f\"original coords: {df['lat'].notna().sum()}\")\n",
    "print(f\"imputed coords: {(df['lat'].isna() & df['final_lat'].notna()).sum()}\")\n",
    "print(f\"still missing: {df['final_lat'].isna().sum()}\")\n",
    "print(f\"coverage: {df['final_lat'].notna().mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up merged df\n",
    "df = df.drop(columns=['imp_lat_x', 'imp_lng_x', 'imp_lat_y', 'imp_lng_y', 'imp_lat', 'imp_lng'], errors='ignore')\n",
    "df.sample(10)\n",
    "df.to_csv(\"policing_imputed_coords.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sds357)",
   "language": "python",
   "name": "sds357"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
